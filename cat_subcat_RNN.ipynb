{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import spacy  # Pour la lemmatisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df_train_csv = pd.read_csv(\"questions_dataset.csv\", header=None, names=[\"data\"])\n",
    "\n",
    "# Prepare an empty list to store transformed rows\n",
    "transformed_data = []\n",
    "\n",
    "# Iterate through each row\n",
    "for _, row in df_train_csv.iterrows():\n",
    "    # Split category into Category and Subcategory\n",
    "    category_parts = row['data'].split(\":\")\n",
    "    classe=category_parts[0]\n",
    "    question_split=category_parts[1]\n",
    "    # Split Question into Label and the rest\n",
    "    label_question= question_split.split(' ')\n",
    "    label = label_question[0]  \n",
    "    question_rest =  \" \".join(label_question[1:])  # The rest as the question  # Remaining part of the question\n",
    "    \n",
    "    # Append the transformed data as a tuple\n",
    "    transformed_data.append(( question_rest,classe, label))\n",
    "\n",
    "# Create a new DataFrame with the transformed data\n",
    "df_train = pd.DataFrame(transformed_data, columns=[\"Question\",\"Category\", \"Subcategory\"])\n",
    "\n",
    "# Save the transformed DataFrame to a new CSV file\n",
    "df_train.to_csv(\"csv_data_file_for_test3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Open the text file and read line by line\n",
    "with open(\"test_dataset.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Prepare an empty list to store transformed rows\n",
    "transformed_data = []\n",
    "\n",
    "# Iterate through each line in the file\n",
    "for line in lines:\n",
    "    line = line.strip()  # Remove any extra spaces or newlines at the beginning and end\n",
    "    \n",
    "    # Split the line into category and question based on the first ':'\n",
    "    if \":\" in line:\n",
    "        category_parts = line.split(\":\", 1)  # Split into category and the rest of the question\n",
    "        classe = category_parts[0].strip()  # The category part\n",
    "        question = category_parts[1].strip()  # The rest as the question\n",
    "        \n",
    "        # Split the question into label and the rest of the question\n",
    "        label_question = question.split(' ', 1)\n",
    "        label = label_question[0].strip() if len(label_question) > 0 else \"\"\n",
    "        question_rest = label_question[1].strip() if len(label_question) > 1 else \"\"\n",
    "        \n",
    "        # Append the transformed data as a tuple\n",
    "        transformed_data.append((question_rest, classe, label))\n",
    "\n",
    "# Create a new DataFrame with the transformed data\n",
    "df_test = pd.DataFrame(transformed_data, columns=[\"Question\", \"Category\", \"Subcategory\"])\n",
    "\n",
    "# Save the transformed DataFrame to a new CSV file (still can save as CSV even if original was TXT)\n",
    "df_test.to_csv(\"test_txt_for_test3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Load spaCy model for text processing\n",
    "stemmer = PorterStemmer()  # Use the Porter stemming algorithm\n",
    "\n",
    "def preprocess_text_keep_significant_words(text):\n",
    "    doc = nlp(text)  # Analyze the text using spaCy\n",
    "    stemmed_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Skip stop words, except for WH-questions\n",
    "        if token.is_stop and token.tag_ not in [\"WP\", \"WDT\", \"WP$\", \"WRB\"]:\n",
    "            continue  # Skip the stop words that are not WH-questions\n",
    "        \n",
    "        # Stemming of WH-questions\n",
    "        elif token.tag_ in [\"WP\", \"WDT\", \"WP$\", \"WRB\"]:  # WH-question POS tags\n",
    "            lemmatized_token = token.lemma_  # Stemming and lemma WH-questions\n",
    "            stemmed_tokens.append(lemmatized_token)  # Add the stemmed WH-question\n",
    "        else:\n",
    "            lemmatized_token = token.lemma_  # Stemming and lemma for other words\n",
    "            stemmed_tokens.append(lemmatized_token)  # Add the stemmed word\n",
    "    \n",
    "    return ' '.join(stemmed_tokens)  # Return the preprocessed sentence as a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[\"Question\"]\n",
    "X_test = df_test[\"Question\"]\n",
    "\n",
    "# Step 1: Classify into Category\n",
    "y_train_category = df_train[\"Category\"]\n",
    "y_test_category = df_test[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialiser le TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (1,2),max_features=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1569 - loss: 3.4171 - val_accuracy: 0.4200 - val_loss: 2.6904\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.3724 - loss: 2.4825 - val_accuracy: 0.5560 - val_loss: 1.9642\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.5691 - loss: 1.6227 - val_accuracy: 0.6180 - val_loss: 1.6415\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7120 - loss: 1.0524 - val_accuracy: 0.6540 - val_loss: 1.5161\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8265 - loss: 0.6644 - val_accuracy: 0.6800 - val_loss: 1.4452\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8986 - loss: 0.4176 - val_accuracy: 0.6900 - val_loss: 1.4685\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9346 - loss: 0.2804 - val_accuracy: 0.6980 - val_loss: 1.4487\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9603 - loss: 0.1884 - val_accuracy: 0.6980 - val_loss: 1.4877\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9769 - loss: 0.1227 - val_accuracy: 0.7120 - val_loss: 1.4305\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0903 - val_accuracy: 0.7080 - val_loss: 1.4752\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9869 - loss: 0.0724 - val_accuracy: 0.7180 - val_loss: 1.5099\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0491 - val_accuracy: 0.7080 - val_loss: 1.5355\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9935 - loss: 0.0436 - val_accuracy: 0.7120 - val_loss: 1.5386\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9957 - loss: 0.0334 - val_accuracy: 0.7020 - val_loss: 1.6053\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0522 - val_accuracy: 0.6960 - val_loss: 1.6329\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9962 - loss: 0.0260 - val_accuracy: 0.7040 - val_loss: 1.5985\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0263 - val_accuracy: 0.7080 - val_loss: 1.6576\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0169 - val_accuracy: 0.7040 - val_loss: 1.6240\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9952 - loss: 0.0233 - val_accuracy: 0.7140 - val_loss: 1.6214\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9943 - loss: 0.0264 - val_accuracy: 0.7040 - val_loss: 1.7153\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Final Classification Results:\n",
      "                                     Question Category Subcategory  \\\n",
      "0        How far is it from Denver to Aspen ?      NUM        dist   \n",
      "1    What county is Modesto , California in ?      LOC        city   \n",
      "2                           Who was Galileo ?      HUM        desc   \n",
      "3                           What is an atom ?     DESC         def   \n",
      "4            When did Hawaii become a state ?      NUM        date   \n",
      "..                                        ...      ...         ...   \n",
      "495    Who was the 22nd President of the US ?      HUM         ind   \n",
      "496    What is the money they use in Zambia ?     ENTY    currency   \n",
      "497                 How many feet in a mile ?      NUM       count   \n",
      "498       What is the birthstone of October ?     ENTY   substance   \n",
      "499                          What is e-coli ?     DESC         def   \n",
      "\n",
      "    Predicted_Category Predicted_Subcategory  \n",
      "0                  NUM                  dist  \n",
      "1                  LOC                 other  \n",
      "2                  HUM                   ind  \n",
      "3                 DESC                  desc  \n",
      "4                  HUM                   ind  \n",
      "..                 ...                   ...  \n",
      "495                HUM                   ind  \n",
      "496               ENTY             substance  \n",
      "497                NUM                 count  \n",
      "498               DESC                   def  \n",
      "499               DESC                   def  \n",
      "\n",
      "[500 rows x 5 columns]\n",
      "Combined Label Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      ABBR_abb       1.00      1.00      1.00         1\n",
      "      ABBR_exp       0.50      0.62      0.56         8\n",
      "      DESC_def       0.76      0.86      0.81       123\n",
      "     DESC_desc       0.20      0.43      0.27         7\n",
      "   DESC_manner       0.07      0.50      0.12         2\n",
      "   DESC_reason       0.71      0.83      0.77         6\n",
      "   ENTY_animal       0.88      0.44      0.58        16\n",
      "     ENTY_body       1.00      0.50      0.67         2\n",
      "    ENTY_color       1.00      0.80      0.89        10\n",
      "   ENTY_cremat       0.00      0.00      0.00         0\n",
      " ENTY_currency       1.00      0.83      0.91         6\n",
      "   ENTY_dismed       0.00      0.00      0.00         2\n",
      "    ENTY_event       0.00      0.00      0.00         2\n",
      "     ENTY_food       0.33      0.25      0.29         4\n",
      "   ENTY_instru       1.00      1.00      1.00         1\n",
      "     ENTY_lang       1.00      1.00      1.00         2\n",
      "    ENTY_other       0.20      0.17      0.18        12\n",
      "    ENTY_plant       0.00      0.00      0.00         5\n",
      "  ENTY_product       0.00      0.00      0.00         4\n",
      "    ENTY_sport       0.50      1.00      0.67         1\n",
      "ENTY_substance       0.09      0.07      0.08        15\n",
      "   ENTY_symbol       0.00      0.00      0.00         0\n",
      " ENTY_techmeth       1.00      1.00      1.00         1\n",
      "   ENTY_termeq       0.00      0.00      0.00         7\n",
      "      ENTY_veh       0.00      0.00      0.00         4\n",
      "     ENTY_word       0.00      0.00      0.00         0\n",
      "      HUM_desc       0.00      0.00      0.00         3\n",
      "        HUM_gr       0.29      0.67      0.40         6\n",
      "       HUM_ind       0.84      0.95      0.89        55\n",
      "     HUM_title       0.00      0.00      0.00         1\n",
      "      LOC_city       1.00      0.83      0.91        18\n",
      "   LOC_country       0.75      1.00      0.86         3\n",
      "     LOC_mount       0.67      0.67      0.67         3\n",
      "     LOC_other       0.78      0.86      0.82        50\n",
      "     LOC_state       0.64      1.00      0.78         7\n",
      "     NUM_count       0.71      0.56      0.62         9\n",
      "      NUM_date       0.98      0.91      0.95        47\n",
      "      NUM_dist       1.00      0.44      0.61        16\n",
      "     NUM_money       0.00      0.00      0.00         3\n",
      "     NUM_other       0.75      0.50      0.60        12\n",
      "      NUM_perc       1.00      0.33      0.50         3\n",
      "    NUM_period       0.55      0.75      0.63         8\n",
      "     NUM_speed       1.00      0.50      0.67         6\n",
      "      NUM_temp       1.00      0.40      0.57         5\n",
      "    NUM_weight       0.67      0.50      0.57         4\n",
      "\n",
      "      accuracy                           0.70       500\n",
      "     macro avg       0.53      0.49      0.49       500\n",
      "  weighted avg       0.72      0.70      0.69       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alaed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data preparation (same as before)\n",
    "df_train[\"Combined_Label\"] = df_train[\"Category\"] + \"_\" + df_train[\"Subcategory\"]\n",
    "df_test[\"Combined_Label\"] = df_test[\"Category\"] + \"_\" + df_test[\"Subcategory\"]\n",
    "\n",
    "# Text preprocessing\n",
    "X_train_processed = df_train[\"Question\"].apply(preprocess_text_keep_significant_words)\n",
    "X_test_processed = df_test[\"Question\"].apply(preprocess_text_keep_significant_words)\n",
    "\n",
    "# Tokenize the processed text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_processed)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_processed)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_processed)\n",
    "\n",
    "# Pad sequences to ensure equal input length\n",
    "max_sequence_length = 100  # Adjust based on your dataset\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_combined = df_train[\"Combined_Label\"]\n",
    "y_test_combined = df_test[\"Combined_Label\"]\n",
    "\n",
    "# Encode labels (you can also use label encoding or one-hot encoding)\n",
    "labels = list(set(y_train_combined))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "y_train_encoded = np.array([label_to_idx[label] for label in y_train_combined])\n",
    "y_test_encoded = np.array([label_to_idx[label] for label in y_test_combined])\n",
    "\n",
    "# One-hot encoding (optional)\n",
    "y_train_one_hot = to_categorical(y_train_encoded, num_classes=len(labels))\n",
    "y_test_one_hot = to_categorical(y_test_encoded, num_classes=len(labels))\n",
    "\n",
    "# RNN model with LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels), activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train_one_hot, epochs=20, batch_size=32, validation_data=(X_test_pad, y_test_one_hot))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred_encoded = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert predictions back to labels\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "y_pred_combined = [idx_to_label[idx] for idx in y_pred_encoded]\n",
    "\n",
    "# Add predictions to the test dataframe\n",
    "df_test[\"Predicted_Combined_Label\"] = y_pred_combined\n",
    "\n",
    "# Split combined predictions back into Category and Subcategory\n",
    "df_test[\"Predicted_Category\"] = df_test[\"Predicted_Combined_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df_test[\"Predicted_Subcategory\"] = df_test[\"Predicted_Combined_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "# Evaluation\n",
    "print(\"Final Classification Results:\")\n",
    "print(df_test[[\"Question\", \"Category\", \"Subcategory\", \"Predicted_Category\", \"Predicted_Subcategory\"]])\n",
    "\n",
    "# Classification report\n",
    "print(\"Combined Label Classification Report:\")\n",
    "print(classification_report(y_test_combined, y_pred_combined))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
